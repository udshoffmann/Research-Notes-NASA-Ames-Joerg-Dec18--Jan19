\section{XPP: Explaining the Space of Plans through Plan-Property Dependencies (Joerg \& Dan AFOSR Project)}
\label{xpp}

Executive abstract: identify implications over Boolean plan
properties, a la "if a plan has property A then it must have/cannot
have property B"; 2) instead of just computing these implications over
a given set of dependencies, automatically "mine" the task for the
most relevant properties given the user's interests. More details see
Appendix~\ref{xpp-abstract}.

Paper in preparation for IJCAI'19: introduces generic framework;
instantiates that framework with goal-fact-conjunction dependencies in
oversubscription planning (like classical planing but with a single
consumed resource of which not enough is given to achieve all goals);
shows that the analysis for "action constraints" (plan properties
taking the form of propositional formulas over the atoms "plan uses at
least one action from action subset $A_i$", where $A_i$ is from a
given collection of distinguished action subsets) can be compiled into
the analysis of goal-fact-conjunction dependencies; shows that LTL
plan trajectory constraints can be compiled into the analysis of
goal-fact-conjunction dependencies; runs experiments on adapted IPC
benchmarks. Framework section of paper draft see
Appendix~\ref{xpp-framework}.



\subsection{Discussion Notes}
\label{discussion}

\subsubsection{Computation}

\begin{itemize}
\item Compute \plans\ once and then use it for everything?

\item \cool{BDDs for some of these computations? represent the set
  \plans?}

\end{itemize}


\subsubsection{XPP vs User Preferences}

\begin{itemize}
\item PDO relation to preference hierarchy? pref $p$ is stronger than
  $q$ is what it says; but importance to user is not there.

\item In iterative-planning application scenario, user preference
  incomplete is assumed: plan generator cannot generate unique most
  preferred solution with an up-front spec of preferences, else the
  iterative process would be useless.

\item Moving border between hard vs soft constraints as you go along,
  in the iterative process. makes sense both for iterative process and
  for computation.

\item There are three reasons for preference issues between user vs
  computer:

  1. different computational power, ie bounded rationality on part of
  user; eg ``why do we do task A after 4 pm?'' ie a dependency
  $\entails{\plans}{\true}{taskAafter4pm}$, or brilliant computer go
  move not understood by user.

  2. model differences (preconditions etc).

  3. optimization/preference function not fully specified up front.

  Here we don't address 2. (no explicit support for this; could be a
  future combination). 3. is naturally addressed in iterative planning
  process. 1. could be addressed, if we have the right plan properties
  to elucidate the ``causes'' behind a dependency. Interesting
  question for future work, see next subsec and
  Section~\ref{xpp:identify-causes} below.

\item Extension combination with user preferences?

  Combine/multiply/merge PDO with preference model over properties?

  Could eg deal point out inconsistent preferences

\item Ground prefs in the reality of feasible solutions, ie compute
  exact space of feasible preferred solutions. Not sure whether it
  makes sense computationally to first compute the entire PDO for this
  purpose though.

\item Or perhaps a more interactive approach where the PDO is
  navigated guided by user preferences, or vice versa user preferenes
  are navigated guided by the PDO?

\end{itemize}



\subsubsection{Discovering New Properties Relevant to User}

Mining as per proposal: start from seed set \props, compare example
plans with \prop\ vs $\neg \prop$, identify relevant differences based
on some sort of information about what's relevant to user, use
inductive learning to characterize these differenes with new plan
properties,

\begin{itemize}
\item Concrete example in oversubscription planning:

  User declared he cares about scientific objectives and energy
  consumption. Seed property objective A. In example plans with A we
  either don't have B, or don't have C, or consume a lot of energy. In
  example plans without A we sometimes have B and C and low energy
  consumption. Infer new property ``B and C and low energy''.

\item E.g. user worries about load balancing, not in \props; how to
  discover this?

  Proposal mining approach could work in principle, but load blanacing
  (variance) difficult to discover.

\item Make property mining interactive?

  Take inspiration from preference eicitation, in setting where
  analyzed properties are soft goals? Similarity is that we are
  looking for properties relevant to user preference; difference is
  that our goal is easier, we just need relevance, not a specification
  characterizing user preferences exactly.

  \cool{Example critiquing style:} Show a plan, user provides
  properties he likes/does not like, these props are included, and new
  plan is generated keeping the ``like'' while removing the ``don't
  like''?  This setup is very close to what
  \cite{fox:etal:ijcai-ws-17} proposed as a question answering method!
  That method here bcomes instead an input to our comprehensive
  analysis. Nice!

\end{itemize}




\subsubsection{Identifying Causes behind a Dependency}

Scenario: given dependency $\entails{\plans}{\prop}{\propq}$. User
asks ``why does this dependency hold?''. How to answer that question?

Could result in user dialogue of WHY questions going deeper at
selected points.

\begin{itemize}
\item \cool{Refine the set of analyzed (\ie\ ``soft'') plan
  properties?}

  Could serve to make explicit the ``causal chain'' between \prop\ and
  \propq. Need to be targeted at question, and at right abstraction
  level. How to find these plan properties?

  Navigate in lattice of equivalence relations in the PDO? Split
  equivalence classes by introducing new properties making cas
  distinctions within?

  Minimizing number of new properties needed, splitting ``down the
  middle''?

  But how to guide selection of classes and case distinctions? Should
  be linked to planning semantics, eg cause for
  $\entails{\plans}{\true}{taskAafter4pm}$ could be other things that
  must be done before task A, or could be energy consumption at
  different times of day. Critical path analysis / precondition/effect
  analysis / planning sub-problem analysis?

\item \cool{Refine (weaken / strengthen) set of enforced (\ie
  ``hard'') plan properties?}

  Critical path analysis in scheduling relates to identifying causes,
  taking which away removes the issue. Here: the hard constraints
  which cause the dependency.

  $\Rightarrow$ Find minimal weakening of enforced properties under
  which $\entails{\plans}{\prop}{\propq}$ disappears?

  Simple method remove minimal number of enforced properties. More
  complex methods could split enforced properties into case
  distinctions and remove only some of those cases.

  Relation to model abstraction a la ASU? Refining the enforced
  properties until their effect ie the entailment relation in
  \plans\ is reconciled with the user expectations?

\item Refinement on analyzed vs enforced props answer different kinds
  of user questions / provide different approaches towards answering
  WHY?

  hard: which of my requirements are causing
  $\entails{\plans}{\prop}{\propq}$?

  soft: which intermediate properties are on the causal chain leading
  to $\entails{\plans}{\prop}{\propq}$?

  Are these two formally related / usefully combinable?

\end{itemize}







\subsubsection{Concrete Examples to look at}

\begin{itemize}
\item Classical planning blocksworld?

  Could be an option if we wanna go extreme on classical setting, and
  if the blocksworld stuff has phenomena inerestingf to talk a bout
  with plan properties. TBD.

\item Oversubscription rovers.

  Playground for NASA-style things but in simple basic setting.

  ``Classical'' version of oversubscription planning \ie\ classical
  planning but too many goals to achieve given amount of one consumed
  resource.

  Can go for temporal aspects where relevant, including Dan makes
  sense.

\item Crater reconstruction?

  Sun moves, rover has to take images of crater for 3D reconstruction,
  imaging depends on rover and sun location.

  Accurate formulation has complex continuous phenomena/consraints.

  Could go for a simple discrete temporal version in PDDL2.2 ie timed
  initial literals.

\item Mission planning?

  Over-subscription setting in online/mid-term scenario when something
  went wrong and not all objectives can be achieved
  anymore. Properties e.g. achieving an objective, using/not using a
  certain device, energy consumption, meeting/not meeting a deadline.

  The simplest version of this is if some task takes much longer than
  anticipated; as this happens, the ongoing decisions are: 1) keep
  going with this task (because it is important or urgent) and not do
  something else?  2) interrupt this task to do something even more
  important/urgent?  3) stop doing this task because it's not that
  important/urgent and it can be done later? Aside: some tasks take a
  very long time (days), and are interruptible.

  In this setting, the approach would at design-time address questions
  what implications a delay has, according to the model, on other
  tasks; at execution time the approach could serve as an iterative
  planning tool, enforcing delays if the consequences are ok.

  Note though: an inherent limitation here is that, the way the
  approach is formulated with plan properties being Boolean functions,
  that the set of plan properties considered would have to discretize
  the possible time points of task completion, ie the "delays" to
  consider would have to be a fixed set of constants.

\end{itemize}








\subsection{Identifying Causes behind a Dependency}
\label{xpp:identify-causes}

Scenario: given dependency $\entails{\plans}{\prop}{\propq}$. User
asks ``why does this dependency hold?''. How to answer that question?

Could result in user dialogue of WHY questions going deeper at
selected points.

\new{joerg: new thoughts added here}



\subsubsection{Modifying the set of Analyzed Plan Properties}
\label{xpp:identify-causes:analyzed}


Modify \props\ to make explicit the ``causal chain'' between
\prop\ and \propq.



\paragraph{Modification means what?}

First we need a distinction between the properties \props\ currently
being analyzed, and the entire set of candidate properties
\candprops\ that could be in \props.

Modification operators: canonically, adding a new property $p \in
\candprops \setminus \props$. But removing/replacing a property could
also be of interest.

Viewing the modification as abstraction refinement, ie navigation in
lattice of equivalence relations in the PDO, akin to abstraction
refinement lattice: not an immediate correspondence, but could be
useful.

1. in difference to abstractions \props\ covers only a subset of all
possible plan properties, rather than being exhaustive (entire state
space). That is, within each equivalence class we only have a subset
of the equivalent properties, and also the union of equivalence
classes is less than \candprops.

2. while in abstractions we just pretend for states to be equivalent
and are free to change our pretence in any way, here we have an
underlying semantics that fixes how things relate.

What comes closest to a refinement step seems to be this: for some $p
\in \props$, replace $p$ with a set of properties conjoining $p$ with
a case distinction, eg $p \wedge q$ and $p \wedge \neg q$. generally:
select a DNF tautology $\bigvee_{i=1}^n \phi_i$ and replace $p$ with
$\{p \wedge \phi_i\}$. This introduces $n$ equivalence classes each of
which entails $p$ ie is ordered before $\equiv{\plans}{\prop}$ in the
PDO, and where the disjunction of representatives is a member of
$\equiv{\plans}{\prop}$.

There does not seem to be a need though to use only this specific kind
of refinement. Adding arbitrary $p \in \candprops \setminus \props$
can be useful, see the following example.



\paragraph{Example: navigation on a map with fuel consumption}

State variables ``connected'' (static), ``at'', ``fuel'', ``visited''
remembering the locations one has been to; actions ``move''.

Plan properties \candprops\ considered: propositional formulas over
state variable values, where a property is true if the plan satisfies
that formula anywhere along its state trajectory.

There are no enforced plan properties, so \plans\ is the set of all
action sequences are applicable in the initial state.

Concrete example: line of locations $l_{-3} ... l_3$. Initially at
$l_0$. Initial fuel $f$ something with $0 < f < 9$, let's say $f = 8$
for simplicity.

Analyzed properties: initially $visited(l_{-3}), visited(l_3), \neg
visited(l_{-3}), \neg visited(l_3)$. As there is not enough fuel to
visit both, we get the dependencies
$\entails{\plans}{visited(l_{-3})}{\neg visited(l_3)}$ and
$\entails{\plans}{visited(l_3)}{\neg visited(l_{-3})}$. 

To answer a WHY question reg these dependencies, how do we modify
\props? It seems what we need to do is add conjunctions capturing the
prerequisites for visiting both $l_{-3}$ and $l_3$. 

This seems to relate to finding a set $C$ of conjunctions leading to
$h^C(I) = \infty$ ... not sure though it's really the same thing.

If we add the properties $\{at(l_i)\}$ then we get dependencies of the
form $\entails{\plans}{at(l_i)}{at(l_{i-1})}$ for $i > 0$ and
$\entails{\plans}{at(l_{i+1})}{at(l_{i})}$ for $i < 0$, as well as
$\entails{\plans}{visited(l_{-3})}{at(l_{-3})}$ and
$\entails{\plans}{visited(l_{3})}{at(l_{3})}$.

This needs to be further refined. 

Consider properties of the form $\{visited(l_{3}) \wedge at(l_i)
\wedge fuel \leq x\}$. \joerg{TBD}


Note that we're leaving the realm of
propositional formulas \candprops\ here, adding numeric inequalities
over resources into the bargain. We have the dependencies:
$\entails{\plans}{visited(l_{3})}{visited(l_{3}) \wedge at(l_{3})
  \wedge fuel \leq 5}$, $\entails{\plans}{visited(l_{3}) \wedge
  at(l_{3}) \wedge fuel \leq 5}{visited(l_{3}) \wedge at(l_{2}) \wedge
  fuel \leq 6}$, $\entails{\plans}{at(l_{2}) \wedge fuel \leq
  6}{at(l_{1}) \wedge fuel \leq 7}$, $\entails{\plans}{at(l_{1})
  \wedge fuel \leq 7}{at(l_{0}) \wedge fuel \leq 8}$. Note that we're
leaving the realm of propositional formulas \candprops\ here, adding
numeric inequalities over resources into the bargain.

Now we could add properties $\{at(l_i) \wedge fuel \leq 8-i\}$






  


\subsubsection{Modifying the set of Enforced Plan Properties}
\label{xpp:identify-causes:enforced}

  Critical path analysis in scheduling relates to identifying causes,
  taking which away removes the issue. Here: the hard constraints
  which cause the dependency.

  $\Rightarrow$ Find minimal weakening of enforced properties under
  which $\entails{\plans}{\prop}{\propq}$ disappears?

  Simple method remove minimal number of enforced properties. More
  complex methods could split enforced properties into case
  distinctions and remove only some of those cases.

  Relation to model abstraction a la ASU? Refining the enforced
  properties until their effect ie the entailment relation in
  \plans\ is reconciled with the user expectations?















